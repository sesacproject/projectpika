import streamlit as st
import pandas as pd
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain.memory import ConversationBufferMemory
import os
# OpenAI API ì„¤ì •
os.environ["OPENAI_API_KEY"] = ""  # ì‹¤ì œ API í‚¤ ì…ë ¥
# Streamlit ì œëª©
st.title("ğŸ’¬ í™”ì¥í’ˆ ì¶”ì²œ ì±—ë´‡ í”¼ì¹´ì¶” âš¡")
# CSV íŒŒì¼ ê²½ë¡œ
csv_file_path = "data/total_reviews.csv"
# ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []
# ë²¡í„°ìŠ¤í† ì–´ì™€ QA ì²´ì¸ ì´ˆê¸°í™”
if "qa_chain" not in st.session_state:
    if os.path.exists(csv_file_path):
        try:
            # CSV íŒŒì¼ ë¡œë“œ
            df = pd.read_csv(csv_file_path)
            # í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬
            if 'ë¶ˆìš©ì–´ ì œê±° ë¦¬ë·°' in df.columns:
                text_data = "\n".join(df['ë¶ˆìš©ì–´ ì œê±° ë¦¬ë·°'].dropna())
            else:
                text_data = "\n".join(df.iloc[:, 0].dropna())
            # í…ìŠ¤íŠ¸ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=150)
            split_docs = text_splitter.split_text(text_data)
            # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            embeddings = OpenAIEmbeddings()
            vectorstore = FAISS.from_texts(split_docs, embeddings)
            # ë©”ëª¨ë¦¬ ìƒì„±
            memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
            # QA ì²´ì¸ ìƒì„±
            llm = ChatOpenAI(
                model_name="gpt-4o",
                temperature=0.2,
                openai_api_key=os.environ.get("OPENAI_API_KEY")
            )
            retriever = vectorstore.as_retriever(search_kwargs={"k": 500})
            st.session_state["qa_chain"] = RetrievalQA.from_chain_type(
                llm=llm,
                retriever=retriever,
                memory=memory
            )
        except Exception as e:
            st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()
    else:
        st.error(f"CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_file_path}")
        st.stop()
# ì±„íŒ… ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
for msg in st.session_state["chat_history"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
# ì‚¬ìš©ì ì…ë ¥
if user_query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 'ê±´ì„± í”¼ë¶€ì— ì í•©í•œ í¬ë¦¼ ì¶”ì²œ')"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(user_query)
    # ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡
    st.session_state["chat_history"].append({"role": "user", "content": user_query})
    # AI ì‘ë‹µ ì²˜ë¦¬
    if "qa_chain" in st.session_state:
        try:
            response = st.session_state["qa_chain"].run(user_query)
            # AI ì‘ë‹µ ë©”ì‹œì§€ í‘œì‹œ
            with st.chat_message("assistant"):
                st.markdown(response)
            # AI ì‘ë‹µ ê¸°ë¡
            st.session_state["chat_history"].append({"role": "assistant", "content": response})
        except Exception as e:
            st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")