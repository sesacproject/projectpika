{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ GPT API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_key)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_key:\n",
    "    raise ValueError(\"Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "genai.configure(api_key=google_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = \"chat_history_gemini.json\"\n",
    "\n",
    "# # CSV íŒŒì¼ ê²½ë¡œ\n",
    "# csv_file = \"ê²½ë¡œì„¤ì • ê³ ê³ ë§\"\n",
    "\n",
    "# # CSV ë°ì´í„° ë¡œë“œ\n",
    "# def load_csv_data(file_path):\n",
    "#     try:\n",
    "#         return pd.read_csv(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: {file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "# # CSV ë°ì´í„° ë¡œë“œ\n",
    "# csv_data = load_csv_data(csv_file)\n",
    "\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_history():\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding = \"utf-8\") as file:\n",
    "            return json.load(file)\n",
    "    return [{\"role\" : \"system\", \"content\" : \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ í™”ìž¥í’ˆ ì•ˆë‚´ ê°€ì´ë“œìž…ë‹ˆë‹¤\"}]\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ ì €ìž¥ í•¨ìˆ˜\n",
    "def save_history(messages):\n",
    "    with open(path, \"w\", encoding = \"utf-8\",) as file:\n",
    "        json.dump(messages, file, ensure_ascii = False, indent = 4)\n",
    "\n",
    "\n",
    "# gemini ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜\n",
    "def get_completion_from_messages(messages, temperature = 1):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gemini-1.5-flash\",\n",
    "        messages = messages,\n",
    "        temperature = temperature\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì±—ë´‡(í”¼ì¹´ì¶”) : ì›í•˜ì‹œëŠ” í™”ìž¥í’ˆ ì¢…ë¥˜(ì„ ì¼€ì–´, í¬ë¦¼, ì„¸ëŸ¼, ë§ˆìŠ¤í¬)ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\n",
      "ì±—ë´‡ : ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Google Gemini API ì„¤ì •\n",
    "genai.configure(api_key=google_key)\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •\n",
    "system_instruction = \"\"\"ë‹¹ì‹ ì€ ì¹œì ˆí•œ í™”ìž¥í’ˆ ì•ˆë‚´ ê°€ì´ë“œ ì±—ë´‡ëª… í”¼ì¹´ì¶”ì•¼ \n",
    "ë„ˆì˜ ì´ë¦„ì€ í”¼ì¹´ì¸„ê°€ ì•„ë‹Œ í”¼ì¹´ì¶”ì•¼\n",
    "ì§ˆë¬¸ìžê°€ ì›í•˜ëŠ” ì¢…ë¥˜ì˜ í™”ìž¥í’ˆì„ ì¶”ì²œí•´ì¤˜.\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_instruction)\n",
    "\n",
    "# JSON íŒŒì¼ ê²½ë¡œ\n",
    "history_file = \"chat_history_gemini.json\"\n",
    "\n",
    "\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_history():\n",
    "    if os.path.exists(history_file):\n",
    "        with open(history_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            return json.load(file)\n",
    "    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë°˜í™˜\n",
    "    return [{\"role\": \"user\", \"parts\": [system_instruction]}]\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ ì €ìž¥ í•¨ìˆ˜ (ìƒˆë¡œìš´ ëŒ€í™” ë‚´ìš© ì¶”ê°€)\n",
    "def save_history(messages):\n",
    "    if os.path.exists(history_file):\n",
    "        with open(history_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            existing_messages = json.load(file)\n",
    "    else:\n",
    "        existing_messages = []\n",
    "\n",
    "    # ê¸°ì¡´ ë©”ì‹œì§€ì™€ ìƒˆë¡œìš´ ë©”ì‹œì§€ ë³‘í•©\n",
    "    updated_messages = existing_messages + messages\n",
    "\n",
    "# JSON íŒŒì¼ì— ëŒ€í™” ê¸°ë¡ ì €ìž¥\n",
    "def save_history(messages, file_path=history_file):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(messages, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# ëŒ€í™” ì‹œìž‘\n",
    "messages = load_history()\n",
    "print(\"ì±—ë´‡(í”¼ì¹´ì¶”) : ì›í•˜ì‹œëŠ” í™”ìž¥í’ˆ ì¢…ë¥˜(ì„ ì¼€ì–´, í¬ë¦¼, ì„¸ëŸ¼, ë§ˆìŠ¤í¬)ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"ì‚¬ìš©ìž: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"ì¢…ë£Œ\", \"ë‚˜ê°€ê¸°\"]:\n",
    "        print(\"ì±—ë´‡ : ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        save_history(messages)\n",
    "        break\n",
    "\n",
    "    # ì‚¬ìš©ìž ìž…ë ¥ ì¶”ê°€\n",
    "    messages.append({\"role\": \"user\", \"parts\": [user_input]})\n",
    "\n",
    "    # í™”ìž¥í’ˆ ì¢…ë¥˜ ë¬»ê¸°\n",
    "    print(\"ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ë¶€ íƒ€ìž…(ê±´ì„±, ì§€ì„±, ë³µí•©ì„±, ë¯¼ê°ì„±)ê³¼ í”¼ë¶€ ê³ ë¯¼(ì£¼ë¦„ ê³ ë¯¼, ë³´ìŠµ ê³ ë¯¼, ë¯¸ë°± ê³ ë¯¼, ì§„ì • ê³ ë¯¼)ì„ ì•Œë ¤ì£¼ì„¸ìš”\")\n",
    "    skin_input = input(\"ì‚¬ìš©ìž: \")\n",
    "    if skin_input.lower() in [\"exit\", \"quit\", \"ì¢…ë£Œ\", \"ë‚˜ê°€ê¸°\"]:\n",
    "        print(\"ì±—ë´‡ : ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        save_history(messages)\n",
    "        break\n",
    "\n",
    "    # ì‚¬ìš©ìž ìž…ë ¥ ì €ìž¥\n",
    "    messages.append({\"role\": \"user\", \"parts\": [skin_input]})\n",
    "\n",
    "    # AI ì‘ë‹µ ìƒì„±\n",
    "    response = model.generate_content(messages)\n",
    "\n",
    "    # ì‘ë‹µ ì¶”ê°€\n",
    "    messages.append({\"role\": \"assistant\", \"parts\": [response.text]})\n",
    "\n",
    "    # ëŒ€í™” ì¶œë ¥\n",
    "    print(f\"ì±—ë´‡(í”¼ì¹´ì¶”) : {response.text}\")\n",
    "\n",
    "    # ëŒ€í™” ê¸°ë¡ì„ íŒŒì¼ì— ì €ìž¥\n",
    "    save_history(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì±—ë´‡(í”¼ì¹´ì¶”) : ì›í•˜ì‹œëŠ” í™”ìž¥í’ˆ ì¢…ë¥˜(ì„ ì¼€ì–´, í¬ë¦¼, ì„¸ëŸ¼, ë§ˆìŠ¤í¬)ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ë¶€ íƒ€ìž…(ê±´ì„±, ì§€ì„±, ë³µí•©ì„±, ë¯¼ê°ì„±)ê³¼ í”¼ë¶€ ê³ ë¯¼(ì£¼ë¦„ ê³ ë¯¼, ë³´ìŠµ ê³ ë¯¼, ë¯¸ë°± ê³ ë¯¼, ì§„ì • ê³ ë¯¼)ì„ ì•Œë ¤ì£¼ì„¸ìš”\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ì¹´ì¶”ì•¼ìž…ë‹ˆë‹¤! ì§€ì„± í”¼ë¶€ì¸ë° ë³´ìŠµ ê³ ë¯¼ì´ì‹œë¼ë©´,  ì„¸ëŸ¼ ì„ íƒì´ ì¤‘ìš”í•´ìš”!  âœ¨  ì§€ì„± í”¼ë¶€ëŠ” í”¼ì§€ ë¶„ë¹„ê°€ ë§Žì•„ ë²ˆë“¤ê±°ë¦¬ì§€ë§Œ,  í”¼ì§€ê°€ ë§Žë‹¤ê³  í•´ì„œ ìˆ˜ë¶„ê¹Œì§€ ì¶©ë¶„í•˜ë‹¤ëŠ” ê±´ ì•„ë‹ˆì—ìš”.  ìˆ˜ë¶„ ë¶€ì¡±ì€ í”¼ì§€ ë¶„ë¹„ë¥¼ ë”ìš± ì´‰ì§„ì‹œì¼œ  íŠ¸ëŸ¬ë¸”ì„ ì•…í™”ì‹œí‚¬ ìˆ˜ ìžˆë‹µë‹ˆë‹¤.  ê·¸ëž˜ì„œ ì§€ì„± í”¼ë¶€ ë³´ìŠµì€  **ìœ ë¶„ê° ì—†ì´ ìˆ˜ë¶„ì„ ì¶©ë¶„ížˆ ê³µê¸‰**í•˜ëŠ” ê²ƒì´  í•µì‹¬ìž…ë‹ˆë‹¤!\n",
    "\n",
    "\n",
    "**ì¶”ì²œ ì„¸ëŸ¼ ì¢…ë¥˜ ë° ì„±ë¶„:**\n",
    "\n",
    "* **ì ¤ íƒ€ìž… ì„¸ëŸ¼:**  ê°€ë³ê³  ì‚°ëœ»í•œ ì ¤ íƒ€ìž… ì„¸ëŸ¼ì´ ì§€ì„± í”¼ë¶€ì— ì í•©í•´ìš”.  ëˆì ìž„ ì—†ì´ ë¹ ë¥´ê²Œ í¡ìˆ˜ë˜ì–´  ìˆ˜ë¶„ì„ ê³µê¸‰í•˜ê³  ì‚°ëœ»í•œ ë§ˆë¬´ë¦¬ê°ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "* **ížˆì•Œë£¨ë¡ ì‚° ì„¸ëŸ¼:**  ížˆì•Œë£¨ë¡ ì‚°ì€ ìˆ˜ë¶„ì„ ëŒì–´ë‹¹ê¸°ëŠ” ëŠ¥ë ¥ì´ ë›°ì–´ë‚˜  í”¼ë¶€ì— í’ë¶€í•œ ìˆ˜ë¶„ì„ ê³µê¸‰í•´ ì¤ë‹ˆë‹¤.  í•˜ì§€ë§Œ  ë„ˆë¬´ ê³ ë†ì¶• ì œí˜•ì€ ëˆì ì¼ ìˆ˜ ìžˆìœ¼ë‹ˆ  ì ì ˆí•œ ë†ë„ì˜ ì œí’ˆì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ìš”.\n",
    "\n",
    "* **íŒí…Œë†€ (ë¹„íƒ€ë¯¼ B5) ì„¸ëŸ¼:**  í”¼ë¶€ ì§„ì • ë° ìž¬ìƒ íš¨ê³¼ê°€ ë›°ì–´ë‚˜ê³ ,  í”¼ë¶€ ìž¥ë²½ ê°•í™”ì—ë„ ë„ì›€ì„ ì¤ë‹ˆë‹¤.  ê±´ì¡°í•˜ê³  ìžê·¹ë°›ì€ í”¼ë¶€ë¥¼ ì§„ì •ì‹œí‚¤ê³   ìˆ˜ë¶„ì„ ê³µê¸‰í•˜ì—¬  í”¼ë¶€ ì»¨ë””ì…˜ì„ ê°œì„ í•˜ëŠ” ë° íš¨ê³¼ì ìž…ë‹ˆë‹¤.\n",
    "\n",
    "* **ë‹ˆì•„ì‹œë‚˜ë§ˆì´ë“œ ì„¸ëŸ¼:**  í”¼ì§€ ì¡°ì ˆê³¼  í”¼ë¶€ ìž¥ë²½ ê°•í™”ì— ë„ì›€ì„ ì£¼ëŠ” ì„±ë¶„ìœ¼ë¡œ,  ê³¼ë„í•œ í”¼ì§€ ë¶„ë¹„ë¥¼ ì¡°ì ˆí•˜ê³   ìˆ˜ë¶„ ë°¸ëŸ°ìŠ¤ë¥¼ ë§žì¶°ì£¼ëŠ” ë° íš¨ê³¼ì ìž…ë‹ˆë‹¤.  í•˜ì§€ë§Œ  ì²˜ìŒ ì‚¬ìš©í•  ë•ŒëŠ”  í”¼ë¶€ ìžê·¹ì„ í™•ì¸í•˜ë©°  ì†ŒëŸ‰ì”© ì‚¬ìš©í•´ ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "**í”¼í•´ì•¼ í•  ì„±ë¶„:**\n",
    "\n",
    "* **ê³¼ë„í•œ ìœ ë¶„:**  ë¯¸ë„¤ëž„ ì˜¤ì¼, ì‹¤ë¦¬ì½˜ ì˜¤ì¼ ë“± ê³¼ë„í•œ ìœ ë¶„ê°ì„ ì£¼ëŠ” ì„±ë¶„ì€ ëª¨ê³µì„ ë§‰ê³  íŠ¸ëŸ¬ë¸”ì„ ìœ ë°œí•  ìˆ˜ ìžˆìœ¼ë¯€ë¡œ í”¼í•˜ì„¸ìš”.\n",
    "* **ì½”ë©”ë„ì œë‹‰ ì„±ë¶„:**  ëª¨ê³µì„ ë§‰ëŠ” ì„±ë¶„(ì½”ë©”ë„ì œë‹‰ ì„±ë¶„)ì´ í•¨ìœ ëœ ì„¸ëŸ¼ì€ í”¼í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.  ì œí’ˆ ì„¤ëª…ì„ ê¼¼ê¼¼í•˜ê²Œ í™•ì¸í•˜ì„¸ìš”.\n",
    "* **ì•Œì½”ì˜¬:**  ì•Œì½”ì˜¬ ì„±ë¶„ì€  í”¼ë¶€ë¥¼ ê±´ì¡°í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ  ì•Œì½”ì˜¬ í•¨ëŸ‰ì´ ë†’ì€ ì œí’ˆì€ í”¼í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "**ì¶”ê°€ íŒ:**\n",
    "\n",
    "* ì„¸ëŸ¼ì€ í† ë„ˆ ë‹¤ìŒ ë‹¨ê³„ì— ì‚¬ìš©í•˜ê³ ,  ê°€ë²¼ìš´ í¬ë¦¼ì´ë‚˜ ì—ë©€ì „ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ìˆ˜ë¶„ì„ ìž ê°€ì£¼ì„¸ìš”.\n",
    "* ì†ë°”ë‹¥ì— ì ë‹¹ëŸ‰ì„ ëœì–´ ì–¼êµ´ ì „ì²´ì— ë¶€ë“œëŸ½ê²Œ íŽ´ ë°”ë¥´ê³ ,  ê°€ë³ê²Œ ë‘ë“œë ¤ í¡ìˆ˜ì‹œì¼œì£¼ì„¸ìš”.\n",
    "* ê¾¸ì¤€ížˆ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ìš”!\n",
    "\n",
    "\n",
    "ì œí’ˆì„ ì„ íƒí•˜ì‹¤ ë•ŒëŠ”  ì„±ë¶„í‘œë¥¼ ê¼¼ê¼¼í•˜ê²Œ í™•ì¸í•˜ì‹œê³ ,  í”¼ë¶€ì— ìžê·¹ì´ ë˜ì§€ ì•ŠëŠ”ì§€  íŒ¨ì¹˜ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë ¤ìš”.  ë” ê¶ê¸ˆí•œ ì ì´ ìžˆë‹¤ë©´ ì–¸ì œë“ ì§€ ì €ì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”! í”¼ì¹´ì¸„ì•¼ê°€ ë„ì™€ë“œë¦´ê²Œìš”! ðŸ’–\n",
    "\n",
    "ì±—ë´‡ : ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : ì›í•˜ì‹œëŠ” í™”ìž¥í’ˆ ì¢…ë¥˜(ì„ ì¼€ì–´, í¬ë¦¼, ì„¸ëŸ¼, ë§ˆìŠ¤í¬)ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ë¶€ íƒ€ìž…(ê±´ì„±, ì§€ì„±, ë³µí•©ì„±, ë¯¼ê°ì„±)ê³¼ í”¼ë¶€ ê³ ë¯¼(ì£¼ë¦„ ê³ ë¯¼, ë³´ìŠµ ê³ ë¯¼, ë¯¸ë°± ê³ ë¯¼, ì§„ì • ê³ ë¯¼)ì„ ìž…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ê±´ì„±, ì£¼ë¦„)\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : ìž…ë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆ: ê±´ì„±, ì£¼ë¦„\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ë¶€ íƒ€ìž…(ê±´ì„±, ì§€ì„±, ë³µí•©ì„±, ë¯¼ê°ì„±)ê³¼ í”¼ë¶€ ê³ ë¯¼(ì£¼ë¦„ ê³ ë¯¼, ë³´ìŠµ ê³ ë¯¼, ë¯¸ë°± ê³ ë¯¼, ì§„ì • ê³ ë¯¼)ì„ ìž…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ê±´ì„±, ì£¼ë¦„)\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : ì•ˆë…•í•˜ì„¸ìš”! í”¼ì¹´ì¶”ì•¼ìž…ë‹ˆë‹¤!  ê±´ì„± í”¼ë¶€ì— ì£¼ë¦„ ê³ ë¯¼ì´ì‹œë¼ë‹ˆ, ê¼¼ê¼¼í•˜ê²Œ ê´€ë¦¬í•´ ë“œë¦´ê²Œìš”!  ê±´ì„± í”¼ë¶€ëŠ” ìˆ˜ë¶„ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ì£¼ë¦„ì´ ë”ìš± ë„ë“œë¼ì ¸ ë³´ì¼ ìˆ˜ ìžˆìœ¼ë‹ˆ,  ìˆ˜ë¶„ ê³µê¸‰ê³¼ í•¨ê»˜ ì£¼ë¦„ ê°œì„ ì— íš¨ê³¼ì ì¸ ì„±ë¶„ì´ í•¨ìœ ëœ ì„ ì¼€ì–´ ì œí’ˆì„ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”.\n",
    "\n",
    "\n",
    "**ì¶”ì²œ ì„ ì¼€ì–´ ì œí’ˆ (íƒ€ìž…ë³„):**\n",
    "\n",
    "**1. ê³ ë³´ìŠµ, ì•ˆí‹°ì—ì´ì§• ê¸°ëŠ¥ì„± ì„ í¬ë¦¼:**\n",
    "\n",
    "* **íŠ¹ì§•:** ê±´ì„± í”¼ë¶€ì— ê¼­ í•„ìš”í•œ í’ë¶€í•œ ìˆ˜ë¶„ê°ê³¼ í•¨ê»˜ ì£¼ë¦„ ê°œì„ , í”¼ë¶€ íƒ„ë ¥ ê°œì„ ì— ë„ì›€ì„ ì£¼ëŠ” ê¸°ëŠ¥ì„± ì„±ë¶„ì´ í•¨ìœ ëœ ì œí’ˆ. ë°±íƒ í˜„ìƒì´ ì ê³ , ìžì™¸ì„  ì°¨ë‹¨ ì§€ìˆ˜(SPF 50+ PA++++ ì´ìƒ)ê°€ ë†’ì€ ì œí’ˆì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "* **ì¶”ì²œ ì„±ë¶„:** ížˆì•Œë£¨ë¡ ì‚°, ì„¸ë¼ë§ˆì´ë“œ, ì½œë¼ê², ë ˆí‹°ë†€(ì €ë…ìš©), ë‚˜ì´ì•„ì‹ ì•„ë§ˆì´ë“œ, ë¹„íƒ€ë¯¼ C ìœ ë„ì²´ ë“±.  ë‹¨, ë ˆí‹°ë†€ì€ ìžì™¸ì„ ì— ì·¨ì•½í•˜ë¯€ë¡œ, ì €ë…ì— ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "* **ì œí˜•:** í¬ë¦¼, ë¡œì…˜ íƒ€ìž….  ì˜¤ì¼ ì„±ë¶„ì´ í•¨ìœ ëœ ë¦¬ì¹˜í•œ ì œí˜•ì„ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
    "* **ì£¼ì˜ì‚¬í•­:**  ì œí’ˆ ì‚¬ìš© ì „ íŒ¨ì¹˜ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.  ë ˆí‹°ë†€ ì„±ë¶„ì´ í¬í•¨ëœ ì œí’ˆì€ ìžì™¸ì„  ì°¨ë‹¨ì œì™€ í•¨ê»˜ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**2. í†¤ì—… ì„ í¬ë¦¼ (ìˆ˜ë¶„ê° ìžˆëŠ” ì œí˜•):**\n",
    "\n",
    "* **íŠ¹ì§•:** ìžì™¸ì„  ì°¨ë‹¨ ê¸°ëŠ¥ê³¼ í•¨ê»˜ í”¼ë¶€ í†¤ì„ ë°í˜€ì£¼ëŠ” íš¨ê³¼ê°€ ìžˆì–´ í™”ì‚¬í•œ í”¼ë¶€ í‘œí˜„ì„ ì›í•˜ì‹œëŠ” ë¶„ë“¤ì—ê²Œ ì í•©í•©ë‹ˆë‹¤.  í•˜ì§€ë§Œ, í†¤ì—… ê¸°ëŠ¥ì´ ìžˆëŠ” ì œí’ˆì€ í”¼ë¶€ì— ìžê·¹ì„ ì¤„ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ, ê±´ì„± í”¼ë¶€ì´ì‹  ê²½ìš° ìˆ˜ë¶„ê°ì´ ì¶©ë¶„í•œ ì œí’ˆì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
    "* **ì¶”ì²œ ì„±ë¶„:**  ížˆì•Œë£¨ë¡ ì‚°, ì„¸ë¼ë§ˆì´ë“œì™€ ê°™ì´ ìˆ˜ë¶„ì„ ê³µê¸‰í•˜ëŠ” ì„±ë¶„ì´ í•¨ìœ ëœ ì œí’ˆì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "* **ì œí˜•:** ìˆ˜ë¶„ í¬ë¦¼, ì—ì„¼ìŠ¤ íƒ€ìž….\n",
    "\n",
    "\n",
    "**ì¶”ì²œ ë¸Œëžœë“œ (ì˜ˆì‹œ):** *(êµ¬ì²´ì ì¸ ì œí’ˆëª…ì€ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.  í”¼ë¶€ íƒ€ìž…ê³¼ ì·¨í–¥ì— ë”°ë¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ê°€ìž¥ ì¤‘ìš”í•©ë‹ˆë‹¤!)*\n",
    "\n",
    "* **ê³ ê°€ ë¸Œëžœë“œ:**  Estee Lauder, SK-II, Sulwhasoo ë“± (ì•ˆí‹°ì—ì´ì§• ê¸°ëŠ¥ì´ ê°•í™”ëœ ì œí’ˆ ë§ŽìŒ)\n",
    "* **ì¤‘ì €ê°€ ë¸Œëžœë“œ:**  CeraVe, La Roche-Posay,  Dr.Althea ë“± (ê±´ì„± í”¼ë¶€ì— ì¢‹ì€ ë³´ìŠµ ì„±ë¶„ í•¨ìœ  ì œí’ˆ ë§ŽìŒ)\n",
    "\n",
    "\n",
    "**ì œí’ˆ ì„ íƒ íŒ:**\n",
    "\n",
    "* **ìžì™¸ì„  ì°¨ë‹¨ ì§€ìˆ˜ í™•ì¸:** SPF 50+ PA++++ ì´ìƒ ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”.\n",
    "* **ì„±ë¶„ í™•ì¸:**  ìžì‹ ì˜ í”¼ë¶€ íƒ€ìž…ì— ë§žëŠ” ì„±ë¶„ì´ í•¨ìœ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì•Œë ˆë¥´ê¸° ìœ ë°œ ì„±ë¶„ì´ ì—†ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
    "* **í›„ê¸° í™•ì¸:**  ë‹¤ë¥¸ ì‚¬ìš©ìžë“¤ì˜ ë¦¬ë·°ë¥¼ ì°¸ê³ í•˜ì—¬ ì œí’ˆì˜ ì‚¬ìš©ê°ê³¼ íš¨ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
    "* **í…ŒìŠ¤íŠ¸ í›„ êµ¬ë§¤:**  ë§¤ìž¥ì—ì„œ í…ŒìŠ¤íŠ¸ í›„ êµ¬ë§¤í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ì£¼ë¦„ ê°œì„ ì€ ìž¥ê¸°ì ì¸ ê´€ë¦¬ê°€ í•„ìš”í•˜ë¯€ë¡œ, ì„ í¬ë¦¼ê³¼ í•¨ê»˜ ê¾¸ì¤€í•œ ë³´ìŠµ ê´€ë¦¬,  ì£¼ë¦„ ê°œì„  ê¸°ëŠ¥ì„± í™”ìž¥í’ˆ ì‚¬ìš© ë“±ì„ ë³‘í–‰í•˜ëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.  ë” ê¶ê¸ˆí•œ ì ì´ ìžˆìœ¼ë©´ ì–¸ì œë“ ì§€ ì €ì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”!  í”¼ì¹´ì¶”!âš¡\n",
    "\n",
    "ì±—ë´‡ : ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv íŠœí”Œ í˜•ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠœí”Œ í˜•ì‹ìœ¼ë¡œ csv íŒŒì¼ ì €ìž¥\n",
    "file_tuple = (\n",
    "    \"cream_aesturaatobarrier365cream.csv\",\n",
    "    \"cream_drgblacksnailcream.csv\",\n",
    "    \"cream_larocheposaycicaplastbaume.csv\",\n",
    "    \"cream_redblemishclearsoothingcream.csv\",\n",
    "    \"cream_snatureaquasqualanemoisturizingcream.csv\",\n",
    "    \"mask_biodancebiocollagenrealdeepmask.csv\",\n",
    "    \"mask_medihealmadecassosideblemishpad.csv\",\n",
    "    \"mask_medihealteatreeessentialmask.csv\",\n",
    "    \"mask_numbuzinno5vitaminspotlightsheetmask.csv\",\n",
    "    \"mask_torridendiveinlowmolecularhyaluronicacidmask.csv\",\n",
    "    \"serum_cosrxthevitaminc23serum.csv\",\n",
    "    \"serum_greentangerinevitacdarkspotcareserum.csv\",\n",
    "    \"serum_ioperetinolsuperbounceserum.csv\",\n",
    "    \"serum_numbuzin3skinserum.csv\",\n",
    "    \"serum_torridendiveinserum.csv\",\n",
    "    \"suncare_ahcmastersairrichsunstick.csv\",\n",
    "    \"suncare_atheveganreliefsuncream.csv\",\n",
    "    \"suncare_plantnarawaterproofsunspray.csv\",\n",
    "    \"suncare_dalbapinktoneupsuncream.csv\",\n",
    "    \"suncare_roundlabbirchmoisturesuncream.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: streamlit\n",
      "Version: 1.40.2\n",
      "Summary: A faster way to build and share data apps\n",
      "Home-page: https://streamlit.io\n",
      "Author: Snowflake Inc\n",
      "Author-email: hello@streamlit.io\n",
      "License: Apache License 2.0\n",
      "Location: c:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\n",
      "Requires: altair, blinker, cachetools, click, gitpython, numpy, packaging, pandas, pillow, protobuf, pyarrow, pydeck, requests, rich, tenacity, toml, tornado, typing-extensions, watchdog\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì±—ë´‡(í”¼ì¹´ì¶”) : ì›í•˜ì‹œëŠ” í™”ìž¥í’ˆ ì¢…ë¥˜(ì„ ì¼€ì–´, í¬ë¦¼, ì„¸ëŸ¼, ë§ˆìŠ¤í¬)ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\n",
      "ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ë¶€ íƒ€ìž…(ê±´ì„±, ì§€ì„±, ë³µí•©ì„±, ë¯¼ê°ì„±)ê³¼ í”¼ë¶€ ê³ ë¯¼(ì£¼ë¦„ ê³ ë¯¼, ë³´ìŠµ ê³ ë¯¼, ë¯¸ë°± ê³ ë¯¼, ì§„ì • ê³ ë¯¼)ì„ ìž…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ê±´ì„±, ì£¼ë¦„)\n",
      "ì±—ë´‡(í”¼ì¹´ì¶”) : ì•ˆë…•í•˜ì„¸ìš”, í”¼ì¹´ì¶”ì•¼ìž…ë‹ˆë‹¤! ì§€ì„±í”¼ë¶€ì— ì£¼ë¦„ì´ ê³ ë¯¼ì´ì‹œë¼ë‹ˆ,  í”¼ë¶€ íƒ€ìž…ì— ë§žëŠ” ì„ ì¼€ì–´ê°€ ì¤‘ìš”í•˜ê² ë„¤ìš”!  ì§€ì„± í”¼ë¶€ëŠ” ê³¼ë„í•œ í”¼ì§€ ë¶„ë¹„ë¡œ ì¸í•´ ë²ˆë“¤ê±°ë¦¼ì´ ì‹¬í•˜ê³ ,  ëª¨ê³µì´ ë§‰ížˆê¸° ì‰¬ì›Œ íŠ¸ëŸ¬ë¸”ì´ ë°œìƒí•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.  ì£¼ë¦„ ê³ ë¯¼ê¹Œì§€ ìžˆë‹¤ë©´,  ê°€ë³ê³  ì‚°ëœ»í•˜ë©´ì„œë„ ìžì™¸ì„  ì°¨ë‹¨ íš¨ê³¼ê°€ ë›°ì–´ë‚œ ì œí’ˆì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.  ë‹¨ìˆœížˆ ë²ˆë“¤ê±°ë¦¼ë§Œ ë°©ì§€í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼,  í”¼ë¶€ì— ìžê·¹ì„ ì£¼ì§€ ì•Šê³  ê¼¼ê¼¼í•˜ê²Œ ìžì™¸ì„ ì„ ì°¨ë‹¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ìš”!\n",
      "\n",
      "\n",
      "**ì§€ì„± í”¼ë¶€ & ì£¼ë¦„ ê³ ë¯¼ì„ ìœ„í•œ ì„ ì¼€ì–´ ì œí’ˆ ì„ íƒ ê°€ì´ë“œ:**\n",
      "\n",
      "* **ê°€ë²¼ìš´ ì œí˜•:**  ì ¤ íƒ€ìž…, ì—ì„¼ìŠ¤ íƒ€ìž…, í”Œë£¨ì´ë“œ íƒ€ìž… ë“± ê°€ë³ê³  ì‚°ëœ»í•œ ì œí˜•ì„ ì„ íƒí•˜ì„¸ìš”. í¬ë¦¼ì´ë‚˜ ë¡œì…˜ íƒ€ìž…ì€ í”¼ë¶€ì— ë¬´ê²ê²Œ ëŠê»´ì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "* **ë²ˆë“¤ê±°ë¦¼ ë°©ì§€:**  ì„¸ë²” ì»¨íŠ¸ë¡¤ ê¸°ëŠ¥ì´ ìžˆëŠ” ì œí’ˆì„ ì„ íƒí•˜ë©´ ë²ˆë“¤ê±°ë¦¼ì„ ì˜ˆë°©í•˜ëŠ”ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
      "* **ìžì™¸ì„  ì°¨ë‹¨ ì§€ìˆ˜:** SPF 50+ PA++++ ì´ìƒì˜ ì œí’ˆì„ ì„ íƒí•˜ì—¬ ê°•ë ¥í•œ ìžì™¸ì„  ì°¨ë‹¨ íš¨ê³¼ë¥¼ ì–»ìœ¼ì„¸ìš”.\n",
      "* **ë¬´ê¸°ìžì°¨ or ìœ ê¸°ìžì°¨:**  ë¬´ê¸°ìžì°¨ëŠ” ë°±íƒ í˜„ìƒì´ ìžˆì„ ìˆ˜ ìžˆì§€ë§Œ ìžê·¹ì´ ì ê³ , ìœ ê¸°ìžì°¨ëŠ” ë°±íƒ í˜„ìƒì´ ì ì§€ë§Œ ìžê·¹ì´ ìžˆì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.  ìžì‹ ì˜ í”¼ë¶€ íƒ€ìž…ì— ë§žëŠ” ê²ƒì„ ì„ íƒí•˜ì„¸ìš”.  ë¯¼ê°í•œ í”¼ë¶€ë¼ë©´ ë¬´ê¸°ìžì°¨ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "* **í•­ì‚°í™” ì„±ë¶„:** ë¹„íƒ€ë¯¼ C ìœ ë„ì²´, ë¹„íƒ€ë¯¼ E ë“±ì˜ í•­ì‚°í™” ì„±ë¶„ì´ í•¨ìœ ëœ ì œí’ˆì„ ì„ íƒí•˜ë©´ ê´‘ë…¸í™”ë¥¼ ì˜ˆë°©í•˜ëŠ”ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
      "* **ì €ìžê·¹ í¬ë®¬ëŸ¬:**  í”¼ë¶€ íŠ¸ëŸ¬ë¸”ì„ ìœ ë°œí•  ìˆ˜ ìžˆëŠ” í–¥ë£Œ, ìƒ‰ì†Œ, íŒŒë¼ë²¤ ë“±ì˜ ì„±ë¶„ì´ ì—†ëŠ” ì €ìžê·¹ ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”.\n",
      "\n",
      "\n",
      "**ì¶”ì²œ ë¸Œëžœë“œ ë° ì„±ë¶„ (ì˜ˆì‹œ):** *(êµ¬ì²´ì ì¸ ì œí’ˆëª…ì€ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.  í”¼ë¶€ íƒ€ìž…ê³¼ ì·¨í–¥ì— ë”°ë¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ê°€ìž¥ ì¤‘ìš”í•©ë‹ˆë‹¤!)*\n",
      "\n",
      "* **ê°€ë²¼ìš´ ì ¤ íƒ€ìž… ì„ í¬ë¦¼:**  ížˆì•Œë£¨ë¡ ì‚°, íŒí…Œë†€ ë“±ì˜ ìˆ˜ë¶„ ì„±ë¶„ í•¨ìœ  ì œí’ˆ.  (ì˜ˆ:  ëª‡ëª‡ ë¸Œëžœë“œì—ì„œ  \"ì ¤ ì„ í¬ë¦¼\" ë˜ëŠ” \"ì—ì„¼ìŠ¤ ì„ í¬ë¦¼\"ìœ¼ë¡œ ê²€ìƒ‰í•˜ë©´ ì°¾ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.)\n",
      "* **ì„¸ë²” ì»¨íŠ¸ë¡¤ ê¸°ëŠ¥ì„± ì„ í¬ë¦¼:**  í”¼ì§€ ì¡°ì ˆ ì„±ë¶„ (ì˜ˆ: ì‚´ë¦¬ì‹¤ì‚°, í‹°íŠ¸ë¦¬ ì˜¤ì¼ ë“±) í•¨ìœ  ì œí’ˆ.  (ì£¼ì˜:  í”¼ì§€ ì¡°ì ˆ ì„±ë¶„ì€ ìžê·¹ì„ ìœ ë°œí•  ìˆ˜ ìžˆìœ¼ë¯€ë¡œ,  ë¯¼ê°ì„± í”¼ë¶€ëŠ” ì£¼ì˜í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.)\n",
      "\n",
      "\n",
      "**ì¶”ê°€ íŒ:**\n",
      "\n",
      "* ì™¸ì¶œ 30ë¶„ ì „ì— ì¶©ë¶„ížˆ ë°”ë¥´ê³ ,  2~3ì‹œê°„ë§ˆë‹¤ ë§ë°œë¼ ì£¼ì„¸ìš”.\n",
      "* ìœ ë¶„ê¸°ê°€ ë§Žì€ ì œí’ˆì€ í”¼í•˜ê³ ,  ë©”ì´í¬ì—… ì „ì— ì‚¬ìš©í•  ê²½ìš° ë©”ì´í¬ì—… ë² ì´ìŠ¤ì™€ì˜ ì¡°í•©ì„ ê³ ë ¤í•˜ì„¸ìš”.\n",
      "* ì €ë…ì—ëŠ” ì£¼ë¦„ ê°œì„ ì— ë„ì›€ì´ ë˜ëŠ” ì„¸ëŸ¼ì´ë‚˜ í¬ë¦¼ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ì œê°€ ë“œë¦° ì •ë³´ê°€ ì§€ì„± í”¼ë¶€ì™€ ì£¼ë¦„ ê³ ë¯¼ì„ í•´ê²°í•˜ëŠ” ë° ë„ì›€ì´ ë˜ê¸°ë¥¼ ë°”ëžë‹ˆë‹¤.  ë” ê¶ê¸ˆí•œ ì ì´ ìžˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!  í”¼ì¹´ì¶”!âš¡\n",
      "\n",
      "ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ë¶€ íƒ€ìž…(ê±´ì„±, ì§€ì„±, ë³µí•©ì„±, ë¯¼ê°ì„±)ê³¼ í”¼ë¶€ ê³ ë¯¼(ì£¼ë¦„ ê³ ë¯¼, ë³´ìŠµ ê³ ë¯¼, ë¯¸ë°± ê³ ë¯¼, ì§„ì • ê³ ë¯¼)ì„ ìž…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ê±´ì„±, ì£¼ë¦„)\n",
      "ì±—ë´‡(í”¼ì¹´ì¶”) : ìž…ë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆ: ê±´ì„±, ì£¼ë¦„\n",
      "ì±—ë´‡ : ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Google Gemini API ì„¤ì •\n",
    "genai.configure(api_key=google_key)\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •\n",
    "# csv íŒŒì¼ì„ ì½ì–´ì˜¤ëŠ” í”„ë¡¬í”„íŠ¸ ìž‘ì„±\n",
    "system_instruction = \"\"\"ë‹¹ì‹ ì€ ì¹œì ˆí•œ í™”ìž¥í’ˆ ì•ˆë‚´ ê°€ì´ë“œ ì±—ë´‡ëª… í”¼ì¹´ì¶”ì•¼ \n",
    "ë„ˆì˜ ì´ë¦„ì€ í”¼ì¹´ì¸„ê°€ ì•„ë‹Œ í”¼ì¹´ì¶”ì•¼\n",
    "ì§ˆë¬¸ìžê°€ ì›í•˜ëŠ” ì¢…ë¥˜ì˜ í™”ìž¥í’ˆì„ ì¶”ì²œí•´ì¤˜.\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_instruction)\n",
    "\n",
    "# ëª¨ë“  íŒŒì¼ì„ ë°˜ë³µí•˜ë©° ì½ê¸°\n",
    "# ë³€ìˆ˜ëª… ë³€ê²½\n",
    "# for file in file_tuple:\n",
    "#     data = pd.read_csv(file)\n",
    "#     print(f\"{file}ì˜ ë°ì´í„°:\\n\", data.head())\n",
    "\n",
    "# JSON íŒŒì¼ ê²½ë¡œ\n",
    "history_file = \"test_history.json\"\n",
    "csv_file = \"cream_aesturaatobarrier365cream.csv\"\n",
    "\n",
    "# CSV ë°ì´í„° ë¡œë“œ í•¨ìˆ˜\n",
    "def load_csv_data(file_path):\n",
    "    try:\n",
    "        return pd.read_csv(file_path, header=None, names=[\"ë¦¬ë·°\"])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    \n",
    "\n",
    "# CSV ë°ì´í„° ë¡œë“œ\n",
    "csv_data = load_csv_data(csv_file)\n",
    "\n",
    "# í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬ë·° ê²€ìƒ‰\n",
    "def search_reviews(keywords):\n",
    "    if csv_data.empty:\n",
    "        return \"CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "    # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¦¬ë·° ê²€ìƒ‰\n",
    "    matched_reviews = csv_data[csv_data[\"ë¦¬ë·°\"].str.contains('|'.join(keywords), na=False)]\n",
    "    if matched_reviews.empty:\n",
    "        return \"í•´ë‹¹ í‚¤ì›Œë“œì— ë§žëŠ” ë¦¬ë·°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    return matched_reviews[\"ë¦¬ë·°\"].to_string(index=False)\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_history():\n",
    "    if os.path.exists(history_file):\n",
    "        with open(history_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            return json.load(file)\n",
    "    return [{\"role\": \"user\", \"parts\": [system_instruction]}]\n",
    "\n",
    "# JSON íŒŒì¼ì— ëŒ€í™” ê¸°ë¡ ì €ìž¥\n",
    "def save_history(messages, file_path=history_file):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(messages, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# ëŒ€í™” ì‹œìž‘\n",
    "messages = load_history()\n",
    "print(\"ì±—ë´‡(í”¼ì¹´ì¶”) : ì›í•˜ì‹œëŠ” í™”ìž¥í’ˆ ì¢…ë¥˜(ì„ ì¼€ì–´, í¬ë¦¼, ì„¸ëŸ¼, ë§ˆìŠ¤í¬)ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"ì‚¬ìš©ìž: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"ì¢…ë£Œ\", \"ë‚˜ê°€ê¸°\"]:\n",
    "        print(\"ì±—ë´‡ : ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        save_history(messages)\n",
    "        break\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"parts\": [user_input]})\n",
    "\n",
    "    print(\"ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ë¶€ íƒ€ìž…(ê±´ì„±, ì§€ì„±, ë³µí•©ì„±, ë¯¼ê°ì„±)ê³¼ í”¼ë¶€ ê³ ë¯¼(ì£¼ë¦„ ê³ ë¯¼, ë³´ìŠµ ê³ ë¯¼, ë¯¸ë°± ê³ ë¯¼, ì§„ì • ê³ ë¯¼)ì„ ìž…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ê±´ì„±, ì£¼ë¦„)\")\n",
    "    skin_input = input(\"ì‚¬ìš©ìž: \")\n",
    "\n",
    "    # ìž…ë ¥ ìœ íš¨ì„± ê²€ì‚¬\n",
    "    if skin_input.lower() in [\"exit\", \"quit\", \"ì¢…ë£Œ\", \"ë‚˜ê°€ê¸°\"]:\n",
    "        print(\"ì±—ë´‡ : ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        save_history(messages)\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        skin_type, concern = map(str.strip, skin_input.split(','))\n",
    "    except ValueError:\n",
    "        print(\"ì±—ë´‡(í”¼ì¹´ì¶”) : ìž…ë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆ: ê±´ì„±, ì£¼ë¦„\")\n",
    "        continue\n",
    "\n",
    "    # í‚¤ì›Œë“œ ê¸°ë°˜ ë¦¬ë·° ê²€ìƒ‰\n",
    "    csv_result = search_reviews([skin_type, concern])\n",
    "\n",
    "    # ëª¨ë¸ì— ê²€ìƒ‰ ê²°ê³¼ ì „ë‹¬\n",
    "    if \"ë¦¬ë·°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\" in csv_result:\n",
    "        model_input = f\"í”¼ë¶€ íƒ€ìž…: {skin_type}, ê³ ë¯¼: {concern}. {csv_result}\"\n",
    "    else:\n",
    "        model_input = f\"í”¼ë¶€ íƒ€ìž…: {skin_type}, ê³ ë¯¼: {concern}. ê´€ë ¨ ë¦¬ë·°:\\n{csv_result}\"\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"parts\": [model_input]})\n",
    "\n",
    "    # AI ì‘ë‹µ ìƒì„±\n",
    "    response = model.generate_content(messages)\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"parts\": [response.text]})\n",
    "    print(f\"ì±—ë´‡(í”¼ì¹´ì¶”) : {response.text}\")\n",
    "\n",
    "    save_history(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì±—ë´‡(í”¼ì¹´ì¶”) : ì›í•˜ì‹œëŠ” í™”ìž¥í’ˆ ì¢…ë¥˜(ì„ ì¼€ì–´, í¬ë¦¼, ì„¸ëŸ¼, ë§ˆìŠ¤í¬)ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ë¶€ íƒ€ìž…(ê±´ì„±, ì§€ì„±, ë³µí•©ì„±, ë¯¼ê°ì„±)ê³¼ í”¼ë¶€ ê³ ë¯¼(ì£¼ë¦„ ê³ ë¯¼, ë³´ìŠµ ê³ ë¯¼, ë¯¸ë°± ê³ ë¯¼, ì§„ì • ê³ ë¯¼)ì„ ì•Œë ¤ì£¼ì„¸ìš”\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ì¹´ì¶”ì•¼ìž…ë‹ˆë‹¤! ì§€ì„± í”¼ë¶€ì¸ë° ë³´ìŠµ ê³ ë¯¼ì´ì‹œë¼ë©´,  ì„¸ëŸ¼ ì„ íƒì´ ì¤‘ìš”í•´ìš”!  âœ¨  ì§€ì„± í”¼ë¶€ëŠ” í”¼ì§€ ë¶„ë¹„ê°€ ë§Žì•„ ë²ˆë“¤ê±°ë¦¬ì§€ë§Œ,  í”¼ì§€ê°€ ë§Žë‹¤ê³  í•´ì„œ ìˆ˜ë¶„ê¹Œì§€ ì¶©ë¶„í•˜ë‹¤ëŠ” ê±´ ì•„ë‹ˆì—ìš”.  ìˆ˜ë¶„ ë¶€ì¡±ì€ í”¼ì§€ ë¶„ë¹„ë¥¼ ë”ìš± ì´‰ì§„ì‹œì¼œ  íŠ¸ëŸ¬ë¸”ì„ ì•…í™”ì‹œí‚¬ ìˆ˜ ìžˆë‹µë‹ˆë‹¤.  ê·¸ëž˜ì„œ ì§€ì„± í”¼ë¶€ ë³´ìŠµì€  **ìœ ë¶„ê° ì—†ì´ ìˆ˜ë¶„ì„ ì¶©ë¶„ížˆ ê³µê¸‰**í•˜ëŠ” ê²ƒì´  í•µì‹¬ìž…ë‹ˆë‹¤!\n",
    "\n",
    "\n",
    "**ì¶”ì²œ ì„¸ëŸ¼ ì¢…ë¥˜ ë° ì„±ë¶„:**\n",
    "\n",
    "* **ì ¤ íƒ€ìž… ì„¸ëŸ¼:**  ê°€ë³ê³  ì‚°ëœ»í•œ ì ¤ íƒ€ìž… ì„¸ëŸ¼ì´ ì§€ì„± í”¼ë¶€ì— ì í•©í•´ìš”.  ëˆì ìž„ ì—†ì´ ë¹ ë¥´ê²Œ í¡ìˆ˜ë˜ì–´  ìˆ˜ë¶„ì„ ê³µê¸‰í•˜ê³  ì‚°ëœ»í•œ ë§ˆë¬´ë¦¬ê°ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "* **ížˆì•Œë£¨ë¡ ì‚° ì„¸ëŸ¼:**  ížˆì•Œë£¨ë¡ ì‚°ì€ ìˆ˜ë¶„ì„ ëŒì–´ë‹¹ê¸°ëŠ” ëŠ¥ë ¥ì´ ë›°ì–´ë‚˜  í”¼ë¶€ì— í’ë¶€í•œ ìˆ˜ë¶„ì„ ê³µê¸‰í•´ ì¤ë‹ˆë‹¤.  í•˜ì§€ë§Œ  ë„ˆë¬´ ê³ ë†ì¶• ì œí˜•ì€ ëˆì ì¼ ìˆ˜ ìžˆìœ¼ë‹ˆ  ì ì ˆí•œ ë†ë„ì˜ ì œí’ˆì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ìš”.\n",
    "\n",
    "* **íŒí…Œë†€ (ë¹„íƒ€ë¯¼ B5) ì„¸ëŸ¼:**  í”¼ë¶€ ì§„ì • ë° ìž¬ìƒ íš¨ê³¼ê°€ ë›°ì–´ë‚˜ê³ ,  í”¼ë¶€ ìž¥ë²½ ê°•í™”ì—ë„ ë„ì›€ì„ ì¤ë‹ˆë‹¤.  ê±´ì¡°í•˜ê³  ìžê·¹ë°›ì€ í”¼ë¶€ë¥¼ ì§„ì •ì‹œí‚¤ê³   ìˆ˜ë¶„ì„ ê³µê¸‰í•˜ì—¬  í”¼ë¶€ ì»¨ë””ì…˜ì„ ê°œì„ í•˜ëŠ” ë° íš¨ê³¼ì ìž…ë‹ˆë‹¤.\n",
    "\n",
    "* **ë‹ˆì•„ì‹œë‚˜ë§ˆì´ë“œ ì„¸ëŸ¼:**  í”¼ì§€ ì¡°ì ˆê³¼  í”¼ë¶€ ìž¥ë²½ ê°•í™”ì— ë„ì›€ì„ ì£¼ëŠ” ì„±ë¶„ìœ¼ë¡œ,  ê³¼ë„í•œ í”¼ì§€ ë¶„ë¹„ë¥¼ ì¡°ì ˆí•˜ê³   ìˆ˜ë¶„ ë°¸ëŸ°ìŠ¤ë¥¼ ë§žì¶°ì£¼ëŠ” ë° íš¨ê³¼ì ìž…ë‹ˆë‹¤.  í•˜ì§€ë§Œ  ì²˜ìŒ ì‚¬ìš©í•  ë•ŒëŠ”  í”¼ë¶€ ìžê·¹ì„ í™•ì¸í•˜ë©°  ì†ŒëŸ‰ì”© ì‚¬ìš©í•´ ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "**í”¼í•´ì•¼ í•  ì„±ë¶„:**\n",
    "\n",
    "* **ê³¼ë„í•œ ìœ ë¶„:**  ë¯¸ë„¤ëž„ ì˜¤ì¼, ì‹¤ë¦¬ì½˜ ì˜¤ì¼ ë“± ê³¼ë„í•œ ìœ ë¶„ê°ì„ ì£¼ëŠ” ì„±ë¶„ì€ ëª¨ê³µì„ ë§‰ê³  íŠ¸ëŸ¬ë¸”ì„ ìœ ë°œí•  ìˆ˜ ìžˆìœ¼ë¯€ë¡œ í”¼í•˜ì„¸ìš”.\n",
    "* **ì½”ë©”ë„ì œë‹‰ ì„±ë¶„:**  ëª¨ê³µì„ ë§‰ëŠ” ì„±ë¶„(ì½”ë©”ë„ì œë‹‰ ì„±ë¶„)ì´ í•¨ìœ ëœ ì„¸ëŸ¼ì€ í”¼í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.  ì œí’ˆ ì„¤ëª…ì„ ê¼¼ê¼¼í•˜ê²Œ í™•ì¸í•˜ì„¸ìš”.\n",
    "* **ì•Œì½”ì˜¬:**  ì•Œì½”ì˜¬ ì„±ë¶„ì€  í”¼ë¶€ë¥¼ ê±´ì¡°í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ  ì•Œì½”ì˜¬ í•¨ëŸ‰ì´ ë†’ì€ ì œí’ˆì€ í”¼í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "**ì¶”ê°€ íŒ:**\n",
    "\n",
    "* ì„¸ëŸ¼ì€ í† ë„ˆ ë‹¤ìŒ ë‹¨ê³„ì— ì‚¬ìš©í•˜ê³ ,  ê°€ë²¼ìš´ í¬ë¦¼ì´ë‚˜ ì—ë©€ì „ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ìˆ˜ë¶„ì„ ìž ê°€ì£¼ì„¸ìš”.\n",
    "* ì†ë°”ë‹¥ì— ì ë‹¹ëŸ‰ì„ ëœì–´ ì–¼êµ´ ì „ì²´ì— ë¶€ë“œëŸ½ê²Œ íŽ´ ë°”ë¥´ê³ ,  ê°€ë³ê²Œ ë‘ë“œë ¤ í¡ìˆ˜ì‹œì¼œì£¼ì„¸ìš”.\n",
    "* ê¾¸ì¤€ížˆ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ìš”!\n",
    "\n",
    "\n",
    "ì œí’ˆì„ ì„ íƒí•˜ì‹¤ ë•ŒëŠ”  ì„±ë¶„í‘œë¥¼ ê¼¼ê¼¼í•˜ê²Œ í™•ì¸í•˜ì‹œê³ ,  í”¼ë¶€ì— ìžê·¹ì´ ë˜ì§€ ì•ŠëŠ”ì§€  íŒ¨ì¹˜ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë ¤ìš”.  ë” ê¶ê¸ˆí•œ ì ì´ ìžˆë‹¤ë©´ ì–¸ì œë“ ì§€ ì €ì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”! í”¼ì¹´ì¸„ì•¼ê°€ ë„ì™€ë“œë¦´ê²Œìš”! ðŸ’–\n",
    "\n",
    "ì±—ë´‡ : ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : ì›í•˜ì‹œëŠ” í™”ìž¥í’ˆ ì¢…ë¥˜(ì„ ì¼€ì–´, í¬ë¦¼, ì„¸ëŸ¼, ë§ˆìŠ¤í¬)ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ë¶€ íƒ€ìž…(ê±´ì„±, ì§€ì„±, ë³µí•©ì„±, ë¯¼ê°ì„±)ê³¼ í”¼ë¶€ ê³ ë¯¼(ì£¼ë¦„ ê³ ë¯¼, ë³´ìŠµ ê³ ë¯¼, ë¯¸ë°± ê³ ë¯¼, ì§„ì • ê³ ë¯¼)ì„ ìž…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ê±´ì„±, ì£¼ë¦„)\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : ì•ˆë…•í•˜ì„¸ìš”! í”¼ì¹´ì¶”ì•¼ìž…ë‹ˆë‹¤! ì§€ì„± í”¼ë¶€ì¸ë° ë³´ìŠµì´ ê³ ë¯¼ì´ì‹œë¼ë‹ˆ,  ì¡°ê¸ˆ íŠ¹ë³„í•œ ì¼€ì–´ê°€ í•„ìš”í•˜ì‹œê² ë„¤ìš”!  ì§€ì„± í”¼ë¶€ëŠ” í”¼ì§€ ë¶„ë¹„ê°€ ë§Žì•„ì„œ ë²ˆë“¤ê±°ë¦¼ì´ ì‹¬í•˜ì§€ë§Œ,  í”¼ë¶€ ì† ìˆ˜ë¶„ì€ ë¶€ì¡±í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.  ê·¸ëž˜ì„œ ë³´ìŠµì€ ì¤‘ìš”í•˜ì§€ë§Œ, ëˆì ì´ê±°ë‚˜ ë¬´ê±°ìš´ ì œí˜•ì€ í”¼í•´ì•¼ í•©ë‹ˆë‹¤.  ê°€ë³ê³  ì‚°ëœ»í•˜ë©´ì„œë„ ê¹Šì€ ë³´ìŠµì„ ì œê³µí•˜ëŠ” ì„¸ëŸ¼ì„ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”!\n",
    "\n",
    "\n",
    "**ì§€ì„± í”¼ë¶€ ë³´ìŠµ ì„¸ëŸ¼ ì„ íƒ ê°€ì´ë“œ:**\n",
    "\n",
    "* **ê°€ë²¼ìš´ ì œí˜•:** ì ¤, ì—ì„¼ìŠ¤ íƒ€ìž…ì˜ ê°€ë²¼ìš´ ì œí˜•ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. í¬ë¦¼ì´ë‚˜ ì˜¤ì¼ íƒ€ìž…ì€ í”¼ë¶€ì— ë¶€ë‹´ì´ ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "* **ìˆ˜ë¶„ ê³µê¸‰ ì„±ë¶„:** ížˆì•Œë£¨ë¡ ì‚°, íŒí…Œë†€, ê¸€ë¦¬ì„¸ë¦° ë“± ìˆ˜ë¶„ì„ ë¨¸ê¸ˆëŠ” ì„±ë¶„ì´ í•¨ìœ ëœ ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”.\n",
    "* **í”¼ì§€ ì¡°ì ˆ ì„±ë¶„:**  í”¼ì§€ ë¶„ë¹„ë¥¼ ì¡°ì ˆí•˜ëŠ” ì„±ë¶„ (ì˜ˆ: ì‚´ë¦¬ì‹¤ì‚°, í‹°íŠ¸ë¦¬ ì˜¤ì¼ ë“±)ì´ í•¨ìœ ëœ ì œí’ˆì´ë¼ë©´ ë”ìš± ì¢‹ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë¯¼ê°ì„± í”¼ë¶€ë¼ë©´ í”¼ì§€ ì¡°ì ˆ ì„±ë¶„ì´ ìžê·¹ì„ ì¤„ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ ì£¼ì˜í•˜ì„¸ìš”.  í”¼ë¶€ í…ŒìŠ¤íŠ¸ í›„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œìž¥í•©ë‹ˆë‹¤.\n",
    "* **í¡ìˆ˜ë ¥:** ë¹ ë¥´ê²Œ í¡ìˆ˜ë˜ëŠ” ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”. ëˆì ìž„ ì—†ì´ ì‚°ëœ»í•˜ê²Œ ë§ˆë¬´ë¦¬ë˜ëŠ” ì œí’ˆì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "* **ë¬´í–¥ë£Œ, ì €ìžê·¹:**  í–¥ë£Œë‚˜ ìžê·¹ì ì¸ ì„±ë¶„ì´ ë“¤ì–´ìžˆì§€ ì•Šì€ ì œí’ˆì„ ì„ íƒí•˜ì—¬ í”¼ë¶€ íŠ¸ëŸ¬ë¸”ì„ ì˜ˆë°©í•˜ì„¸ìš”.\n",
    "\n",
    "\n",
    "**ì¶”ì²œ ì„¸ëŸ¼ ì„±ë¶„ (ì˜ˆì‹œ):**\n",
    "\n",
    "* **ížˆì•Œë£¨ë¡ ì‚°:**  í”¼ë¶€ì— ìˆ˜ë¶„ì„ ê³µê¸‰í•˜ê³  ìœ ì§€í•˜ëŠ” ë° íƒì›”í•œ íš¨ê³¼ë¥¼ ê°€ì§„ ì„±ë¶„ìž…ë‹ˆë‹¤.\n",
    "* **íŒí…Œë†€:**  í”¼ë¶€ ì§„ì • ë° ë³´ìŠµ íš¨ê³¼ê°€ ë›°ì–´ë‚˜ë©°, í”¼ë¶€ ìž¥ë²½ ê°•í™”ì—ë„ ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
    "* **ê¸€ë¦¬ì„¸ë¦°:**  í”¼ë¶€ í‘œë©´ì— ìˆ˜ë¶„ë§‰ì„ í˜•ì„±í•˜ì—¬ ìˆ˜ë¶„ ì¦ë°œì„ ë§‰ì•„ì¤ë‹ˆë‹¤.\n",
    "* **ì„¸ë¼ë§ˆì´ë“œ:**  í”¼ë¶€ ìž¥ë²½ì„ ê°•í™”í•˜ì—¬ ìˆ˜ë¶„ ì†ì‹¤ì„ ì˜ˆë°©í•˜ëŠ” ë° íš¨ê³¼ì ìž…ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "**ì¶”ì²œ ë¸Œëžœë“œ (ì˜ˆì‹œ):** *(êµ¬ì²´ì ì¸ ì œí’ˆëª…ì€ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.  í”¼ë¶€ íƒ€ìž…ê³¼ ì·¨í–¥ì— ë”°ë¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ê°€ìž¥ ì¤‘ìš”í•©ë‹ˆë‹¤!)*\n",
    "\n",
    "* **ì¤‘ì €ê°€ ë¸Œëžœë“œ:**  The Ordinary (ížˆì•Œë£¨ë¡ ì‚° ì„¸ëŸ¼),  Isntree (ížˆì•Œë£¨ë¡ ì‚° ì„¸ëŸ¼),  Cosrx (í”¼ì§€ ì¡°ì ˆ ì„¸ëŸ¼)  ë“± (ê°€ì„±ë¹„ ì¢‹ì€ ì œí’ˆ ë§ŽìŒ)\n",
    "* **ê³ ê°€ ë¸Œëžœë“œ:**  EstÃ©e Lauder, SK-II ë“± (ê³ ê¸°ëŠ¥ì„± ì œí’ˆ ë§ŽìŒ)\n",
    "\n",
    "\n",
    "**ì¶”ê°€ íŒ:**\n",
    "\n",
    "* ì„¸ëŸ¼ì„ ë°”ë¥´ê¸° ì „ì— í† ë„ˆë¡œ í”¼ë¶€ê²°ì„ ì •ëˆí•˜ê³ , ìˆ˜ë¶„ í¬ë¦¼ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ë³´ìŠµ íš¨ê³¼ë¥¼ ë†’ì—¬ì£¼ì„¸ìš”.\n",
    "* ì•„ì¹¨, ì €ë…ìœ¼ë¡œ ê¾¸ì¤€ížˆ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "* ì œí’ˆ ì‚¬ìš© ì „ì— íŒ¨ì¹˜ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ì§€ì„± í”¼ë¶€ ë³´ìŠµì€ ì‰½ì§€ ì•Šì§€ë§Œ,  ì ì ˆí•œ ì œí’ˆì„ ì„ íƒí•˜ê³  ê¾¸ì¤€ížˆ ê´€ë¦¬í•˜ë©´ ì¶©ë¶„ížˆ ê°œì„ ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.  í”¼ì¹´ì¶”ê°€ ì‘ì›í• ê²Œìš”!  ë‹¤ë¥¸ ê¶ê¸ˆí•œ ì ì´ ìžˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!  í”¼ì¹´ì¶”!âš¡\n",
    "\n",
    "ì±—ë´‡(í”¼ì¹´ì¶”) : í”¼ë¶€ íƒ€ìž…(ê±´ì„±, ì§€ì„±, ë³µí•©ì„±, ë¯¼ê°ì„±)ê³¼ í”¼ë¶€ ê³ ë¯¼(ì£¼ë¦„ ê³ ë¯¼, ë³´ìŠµ ê³ ë¯¼, ë¯¸ë°± ê³ ë¯¼, ì§„ì • ê³ ë¯¼)ì„ ìž…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ê±´ì„±, ì£¼ë¦„)\n",
    "ì±—ë´‡ : ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "try:\n",
    "    # CSVLoaderë¡œ ë¬¸ì„œ ë¡œë“œ\n",
    "    loader = CSVLoader(file_path=\"data/total_reviews.csv\")\n",
    "    documents = loader.load()\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ ë¶„í• \n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "    print(\"FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ.\")\n",
    "except Exception as e:\n",
    "    print(f\"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²°ê³¼ 1: ï»¿ë¶ˆìš©ì–´ ì œê±° ë¦¬ë·°: í•œë‹¬ì´ìƒ í›„ê¸° ê²¨ìš¸ì— ì‚¬ìš©í–ˆë˜ í¬ë¦¼ì´ì—ìš” ê±´ì„±í”¼ë¶€ê°€ ê²¨ìš¸ì— ì‚¬ìš©í•˜ê¸°ì—” ë³´ìŠµë ¥ì´ ì•½í•œíŽ¸ì´ì§€ë§Œ ìžê¸°ì „ì— ì•°í”Œ ë¨¼ì € ë°”ë¥´ê³  ìˆ˜ë¶„í¬ë¦¼ ë“¬ë¿ ì˜¬ë ¤ì„œ ìˆ˜ë¶„ ë³´ì¶©ìš©ìœ¼ë¡œ ì‚¬ìš©í–ˆë”ë‹ˆ ê´œì°®ë”ë¼êµ¬ìš” ê±´ì„±í”¼ë¶€ëŠ” ê²¨ìš¸ ì—¬ë¦„ì— ì‚¬ìš©í•˜ê¸° ì¢‹ì„ ì œí’ˆì´ì—ìš” í–¥ì€ ì—†ê³  ê°€ë²¼ìš´ ì œí˜•ì´ì—ìš”\n",
      "í‚¤ì›Œë“œ: í•œë‹¬ì´ìƒ, í›„ê¸°\n",
      "ì œí’ˆëª…: ë‹¥í„°ì§€ ë ˆë“œ ë¸”ë ˆë¯¸ì‰¬ í´ë¦¬ì–´ ìˆ˜ë”© í¬ë¦¼\n",
      "í”¼ë¶€íƒ€ìž…: ë³µí•©ì„±, ê±´ì„±, ì§€ì„±\n",
      "ê¸°ëŠ¥: ë³´ìŠµ, ì§„ì •\n",
      "ì œí’ˆì¢…ë¥˜: í¬ë¦¼\n",
      "ê²°ê³¼ 2: ï»¿ë¶ˆìš©ì–´ ì œê±° ë¦¬ë·°: ê±´ì„±ì˜ ê±´ì„± í”¼ë¶€ë¥¼ ê°€ì§„ 1ì¸ìœ¼ë¡œì¨ ë§Œì¡±í•©ë‹ˆë‹¤\n",
      "í‚¤ì›Œë“œ: ê±´ì„±ì˜, ê±´ì„±\n",
      "ì œí’ˆëª…: ì—ìŠ¤ë„¤ì´ì²˜ ì•„ì¿ ì•„ ìŠ¤ì¿ ì•Œëž€ ìˆ˜ë¶„í¬ë¦¼\n",
      "í”¼ë¶€íƒ€ìž…: ë³µí•©ì„±, ê±´ì„±, ì§€ì„±\n",
      "ê¸°ëŠ¥: ë³´ìŠµ, ì§„ì •\n",
      "ì œí’ˆì¢…ë¥˜: í¬ë¦¼\n",
      "ê²°ê³¼ 3: ï»¿ë¶ˆìš©ì–´ ì œê±° ë¦¬ë·°: ë‚´ ë‚¨ìžì¹œêµ¬ê°€ ì¢‹ì•„í•˜ëŠ” í¬ë¦¼ ê·¸ëŠ” ì§€ì„± í”¼ë¶€ë¥¼ ê°€ì§€ê³  ìžˆê³  í•­ìƒ í¬ë¦¼ì´ ê·¸ì˜ í”¼ë¶€ë¥¼ ì§€ì„±ìœ¼ë¡œ ë§Œë“¤ê³  ë°œì§„ì„ ì¼ìœ¼í‚¨ë‹¤ê³  ë¶ˆí‰í•©ë‹ˆë‹¤ ë‚¨ìžì¹œêµ¬ëŠ” í¬ë¦¼ì„ ì‚¬ìš©í•˜ê¸° ì‹œìž‘í•œ ì´í›„ë¡œ í”¼ë¶€ì˜ í˜¼ëž€ì´ ê°œì„ ë˜ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤ ë‘ê»ê³  ê¸°ë¦„ì§„ ì œí’ˆì„ ë°”ë¥¼ ì—¬ë“œë¦„ì´ ìž˜ ìƒê¸°ëŠ” ì§€ì„± í”¼ë¶€ë¥¼ ê°€ì§„ ì‚¬ëžŒë“¤ì—ê²Œ í¬ë¦¼ì„ ì¶”ì²œí•©ë‹ˆë‹¤\n",
      "í‚¤ì›Œë“œ: ë‚¨ìžì¹œêµ¬ê°€, ì¢‹ì•„í•˜ëŠ”\n",
      "ì œí’ˆëª…: ë‹¥í„°ì§€ ë ˆë“œ ë¸”ë ˆë¯¸ì‰¬ í´ë¦¬ì–´ ìˆ˜ë”© í¬ë¦¼\n",
      "í”¼ë¶€íƒ€ìž…: ë³µí•©ì„±, ê±´ì„±, ì§€ì„±\n",
      "ê¸°ëŠ¥: ë³´ìŠµ, ì§„ì •\n",
      "ì œí’ˆì¢…ë¥˜: í¬ë¦¼\n",
      "ê²°ê³¼ 4: ï»¿ë¶ˆìš©ì–´ ì œê±° ë¦¬ë·°: ìˆ˜ë¶€ì§€í•œí…ŒëŠ” ì í•©í•œ í¬ë¦¼ìž…ë‹ˆë‹¤ ì–¼êµ´ì´ ì—¬ë“œë¦„ì´ ì‹¬í–ˆì—ˆëŠ”ë°ìš” 2ë…„ì§¸ì“°ëŠ”ë° ì–¼êµ´ì´ ì—„ì²­ë‚˜ê²Œ ë‚˜ì•„ì¡ŒìŠµë‹ˆë‹¤ ê¸°ì ì¸ê±°ì£  ì–¼êµ´ì— ë§žì•„ì„œ í–‰ë³µí–ˆìŠµë‹ˆë‹¤ ì´ë ‡ê°œ ê¸´ì‹œê°„ë™ì•ˆ ì œê°€ ë§Žì€ë…¸ë ¥ì„í–ˆëŠ”ë° ê¼­ í¬ë¦¼ì€ ë§¤ì¼ ë°œë¼ì£¼ê³  ë‹¤ë…”ìŠµë‹ˆë‹¤ ë‹¤ë“¤ í¬ë¦¼ ì‚¬ì„¸ìš” ã…œ\n",
      "í‚¤ì›Œë“œ: ìˆ˜ë¶€ì§€í•œí…ŒëŠ”, ì í•©í•œ\n",
      "ì œí’ˆëª…: ë‹¥í„°ì§€ ë ˆë“œ ë¸”ë ˆë¯¸ì‰¬ í´ë¦¬ì–´ ìˆ˜ë”© í¬ë¦¼\n",
      "í”¼ë¶€íƒ€ìž…: ë³µí•©ì„±, ê±´ì„±, ì§€ì„±\n",
      "ê¸°ëŠ¥: ë³´ìŠµ, ì§„ì •\n",
      "ì œí’ˆì¢…ë¥˜: í¬ë¦¼\n",
      "ê²°ê³¼ 5: ï»¿ë¶ˆìš©ì–´ ì œê±° ë¦¬ë·°: êµ¬ì§€ ì œê°€ ì„¤ëª…ì•ˆí•´ë„ ë„ˆë¬´ë„ˆë¬´ ìœ ëª…í•´ì„œ ë‹¤ë“¤ ì•„ì‹œì§€ìš” ì§€ì„±í”¼ë¶€ íŠ¹í™”ëœ í¬ë¦¼ì´ë¼ê³  ìƒê°í•˜ì‹œë©´ ë ê±°ê°™ì•„ìš” í”¼ë¶€ê°€ ë¯¼ê°í•˜ì‹œê±°ë‚˜ ê°€ë²¼ìš´ ë¼ì´íŠ¸í•œ í¬ë¦¼ì„ ì°¾ìœ¼ì‹œëŠ”ë¶„ ì—¬ë¦„ì— ë°”ë¥¼ í¬ë¦¼ì´ í•„ìš”í•˜ì‹ ë¶„ ì œí˜•ì´ ë³´ë©´ ë˜ê²Œ ì ¤ë¦¬ê°™ì€ ì œí˜•ì´ê³  ë°”ë¥´ëŠ”ìˆœê°„ ë¶€ë“œëŸ½ê²Œ ë°œë¼ê³  ì´‰ì´‰í•˜ê³  í¡ìˆ˜ë„ ë¹ ë¥¸íŽ¸ì´ì—ìš” ì €ëŠ” í•œì°½ íŠ¸ëŸ¬ë¸”ì´ í™• ë‚˜ì„œ í”¼ë¶€ê°€ ë’¤ì§‘ì–´ì¡Œì„ë•Œ ëª‡ì£¼ì •ë„ ì´ê±¸ ë°œëžì—ˆëŠ”ë° ì„œì„œí•˜ê²Œ ì§„ì •ì´ ë˜ì–´ì„œ ê·¸í›„ë¶€í„° í”¼ë¶€ì— íŠ¸ëŸ¬ë¸”ë§Œ ë‚˜ë©´ ì´ê±¸ ì‚¬ìš©í•´ì£¼ê³  ìžˆì–´ìš” ëŒ€ì‹  ê±´ì„±ì´ì‹ ë¶„ë“¤ì—ê² ê°€ë²¼ìš´ ì œí˜•ì´ë¼ì„œ ë” ë³´ìŠµì´ ìŽˆ í¬ë¦¼ì„ ì„žì–´ë°”ë¥´ê±°ë‚˜ ì•„ì¹¨ì— í™”ìž¥í•˜ê¸° ì „ì— ë°œë¼ì£¼ì‹œë©´ ë ê±°ê°™ì•„ìš” ì €ëŠ” ì´ê±° í™”ìž¥ì „ì— ë°”ë¥´ë©´ ì¢‹ì•„ìš”ã… ã…  ë°€ë¦¼ë„ ì—†ê³  ë“¤ëœ¸ë„ ì—†ê³  í”¼ë¶€í™”ìž¥ì´ ìž˜ë¨¹ì–´ì„œ ì €ëŠ” ì•„ì¹¨ì—ëŠ” í¬ë¦¼ì„ ì‚¬ìš©í•´ì£¼ê³  ìžˆìŠµë‹ˆë‹¤\n",
      "í‚¤ì›Œë“œ: êµ¬ì§€, ì œê°€\n",
      "ì œí’ˆëª…: ë‹¥í„°ì§€ ë ˆë“œ ë¸”ë ˆë¯¸ì‰¬ í´ë¦¬ì–´ ìˆ˜ë”© í¬ë¦¼\n",
      "í”¼ë¶€íƒ€ìž…: ë³µí•©ì„±, ê±´ì„±, ì§€ì„±\n",
      "ê¸°ëŠ¥: ë³´ìŠµ, ì§„ì •\n",
      "ì œí’ˆì¢…ë¥˜: í¬ë¦¼\n"
     ]
    }
   ],
   "source": [
    "# ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í›„ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰\n",
    "query = \"ê±´ì„± í”¼ë¶€ì— ì í•©í•œ ë³´ìŠµ í¬ë¦¼ ì¶”ì²œ\"\n",
    "results = vectorstore.similarity_search(query, k=5)  # këŠ” ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for idx, result in enumerate(results):\n",
    "    print(f\"ê²°ê³¼ {idx + 1}: {result.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‘ë‹µ: ê±´ì„± í”¼ë¶€ì— ì í•©í•œ ë³´ìŠµ í¬ë¦¼ìœ¼ë¡œëŠ” \"ë‹¥í„°ì§€ ë ˆë“œ ë¸”ë ˆë¯¸ì‰¬ í´ë¦¬ì–´ ìˆ˜ë”© í¬ë¦¼\"ê³¼ \"ì—ìŠ¤ë„¤ì´ì²˜ ì•„ì¿ ì•„ ìŠ¤ì¿ ì•Œëž€ ìˆ˜ë¶„í¬ë¦¼\"ì„ ì¶”ì²œí•©ë‹ˆë‹¤. ë‘ ì œí’ˆ ëª¨ë‘ ê±´ì„± í”¼ë¶€ì— ë³´ìŠµê³¼ ì§„ì • íš¨ê³¼ê°€ ìžˆëŠ” í¬ë¦¼ìž…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "csv_file_path = \"data/total_reviews.csv\"\n",
    "loader = CSVLoader(file_path=csv_file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# OpenAI ìž„ë² ë”© ë° FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "embeddings = OpenAIEmbeddings()  # OpenAI ìž„ë² ë”©\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# Chat Completion ëª¨ë¸ ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)  # Chat Completion ëª¨ë¸\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# ì‚¬ìš©ìž ìž…ë ¥ ì‹¤í–‰\n",
    "user_query = \"ê±´ì„± í”¼ë¶€ì— ì í•©í•œ ë³´ìŠµ í¬ë¦¼ ì¶”ì²œ\"\n",
    "response = qa_chain.run(user_query)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ì‘ë‹µ:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RMARKET\\AppData\\Local\\Temp\\ipykernel_2792\\3827709016.py:21: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)  # Chat Completion ëª¨ë¸\n",
      "C:\\Users\\RMARKET\\AppData\\Local\\Temp\\ipykernel_2792\\3827709016.py:30: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = qa_chain.run(user_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‘ë‹µ: ë§ˆìŠ¤í¬ ì¢…ë¥˜ëŠ” ì´ 4ê°œìž…ë‹ˆë‹¤. ì œí’ˆëª…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. ë©”ë””íž í‹°íŠ¸ë¦¬ ì—ì„¼ì…œ ë§ˆìŠ¤í¬\n",
      "2. ë°”ì´ì˜¤ë˜ìŠ¤ ë°”ì´ì˜¤ ì½œë¼ê² ë¦¬ì–¼ ë”¥ ë§ˆìŠ¤í¬\n",
      "3. ë„˜ë²„ì¦ˆì¸ 5ë²ˆ ê¸€ë£¨íƒ€ì¹˜ì˜¨ì”¨ í”ì  í•„ë¦„íŒ©\n",
      "4. í† ë¦¬ë“  ë‹¤ì´ë¸Œì¸ ì €ë¶„ìž ížˆì•Œë£¨ë¡ ì‚° ë§ˆìŠ¤í¬\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "csv_file_path = \"data/total_reviews.csv\"\n",
    "loader = CSVLoader(file_path=csv_file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=150)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# OpenAI ìž„ë² ë”© ë° FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "embeddings = OpenAIEmbeddings()  # OpenAI ìž„ë² ë”©\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# Chat Completion ëª¨ë¸ ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)  # Chat Completion ëª¨ë¸\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 700}) # ê¸°ë³¸ê°’ k=5\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# ëª¨ë“  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •\n",
    "# response = qa_chain.run(input=user_query, return_all=True)\n",
    "\n",
    "# ì‚¬ìš©ìž ìž…ë ¥ ì‹¤í–‰\n",
    "user_query = \"ë§ˆìŠ¤í¬ ì¢…ë¥˜ ê°œìˆ˜ì™€ ê·¸ ì œí’ˆëª…ì„ ì•Œë ¤ì¤˜. ì¤‘ë³µëœ ì œí’ˆì€ ì œì™¸í•´\"\n",
    "response = qa_chain.run(user_query)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ì‘ë‹µ:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# CSV íŒŒì¼ ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "csv_file_path = \"data/total_reviews.csv\"\n",
    "loader = CSVLoader(file_path=csv_file_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "# OpenAI ìž„ë² ë”© ë° FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "embeddings = OpenAIEmbeddings()  # OpenAI ìž„ë² ë”©\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "# Chat Completion ëª¨ë¸ ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)  # Chat Completion ëª¨ë¸\n",
    "retriever = vectorstore.as_retriever()\n",
    "# RetrievalQA ì²´ì¸ ìƒì„±\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "# ì‚¬ìš©ìž ìž…ë ¥ ì‹¤í–‰\n",
    "user_query = \"ë³µí•©ì„±ì— ì¢‹ì€ í¬ë¦¼ì„ ëª¨ë‘ ì¶”ì²œí•´ì¤˜\"\n",
    "# ëª¨ë“  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •\n",
    "response = qa_chain.run(user_query, return_all=True)\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ì‘ë‹µ:\")\n",
    "for idx, res in enumerate(response):\n",
    "    print(f\"{idx + 1}. {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit-option-menu\n",
      "  Downloading streamlit_option_menu-0.4.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: streamlit>=1.36 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit-option-menu) (1.40.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (4.25.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit>=1.36->streamlit-option-menu) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (1.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from click<9,>=7.0->streamlit>=1.36->streamlit-option-menu) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.36->streamlit-option-menu) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from rich<14,>=10.14.0->streamlit>=1.36->streamlit-option-menu) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from rich<14,>=10.14.0->streamlit>=1.36->streamlit-option-menu) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.36->streamlit-option-menu) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (0.22.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.36->streamlit-option-menu) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (1.16.0)\n",
      "Downloading streamlit_option_menu-0.4.0-py3-none-any.whl (829 kB)\n",
      "   ---------------------------------------- 0.0/829.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/829.3 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 262.1/829.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 829.3/829.3 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: streamlit-option-menu\n",
      "Successfully installed streamlit-option-menu-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit-option-menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.11\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\n",
      "Requires: aiohttp, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-community, langchain-teddynote, ragas\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œìž‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "PIKACHU\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"PIKACHU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model = \"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    # ChatPromptTemplate ëŒ€í™”í˜• í”„ë¡¬í¬íŠ¸\n",
    "    [\n",
    "        (\"system\", \"ë„ˆëŠ” ì¹œì ˆí•œ í™”ìž¥í’ˆ ì•ˆë‚´ ê°€ì´ë“œì•¼ \"),\n",
    "        MessagesPlaceholder(variable_name = \"chat_history\"),\n",
    "        # ì´ì „ ëŒ€í™”ë‚´ìš©ì„ chat_history ì´ë¦„ìœ¼ë¡œ ì €ìž¥í•  ìˆ˜ ìžˆê²Œ í•¨\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages = True, memory_key = \"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history = RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = runnable | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³µí•©ì„± í”¼ë¶€ëŠ” ì¼ë°˜ì ìœ¼ë¡œ Tì¡´(ì´ë§ˆ, ì½”, í„±)ì€ ê¸°ë¦„ì§€ê³ , Uì¡´(ë³¼ê³¼ í„±ì„ )ì€ ê±´ì¡°í•œ íŠ¹ì§•ì„ ê°€ì§€ê³  ìžˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ë‘ ê°€ì§€ í”¼ë¶€ íƒ€ìž…ì„ ê· í˜• ìžˆê²Œ ê´€ë¦¬í•  ìˆ˜ ìžˆëŠ” ì œí’ˆì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ë³µí•©ì„± í”¼ë¶€ì— ì í•©í•œ í™”ìž¥í’ˆ ì¶”ì²œ ëª©ë¡ìž…ë‹ˆë‹¤:\n",
      "\n",
      "1. **í´ë Œì €**:\n",
      "   - ì ¤ íƒ€ìž… í´ë Œì €: í”¼ë¶€ì˜ ìœ ë¶„ì„ ì œê±°í•˜ë©´ì„œë„ ìˆ˜ë¶„ì„ ìœ ì§€í•´ì¤ë‹ˆë‹¤.\n",
      "   - í¼ í´ë Œì €: ê³¼ë„í•œ ìœ ë¶„ì„ ì œê±°í•˜ë©´ì„œë„ í”¼ë¶€ë¥¼ ê±´ì¡°í•˜ê²Œ ë§Œë“¤ì§€ ì•ŠëŠ” ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”.\n",
      "\n",
      "2. **í† ë„ˆ**:\n",
      "   - ì•Œì½”ì˜¬ í”„ë¦¬ í† ë„ˆ: í”¼ë¶€ë¥¼ ì§„ì •ì‹œí‚¤ê³  pH ê· í˜•ì„ ë§žì¶”ì–´ì¤ë‹ˆë‹¤.\n",
      "   - ìˆ˜ë¶„ ê³µê¸‰ì´ ê°€ëŠ¥í•œ í† ë„ˆ: ê±´ì¡°í•œ ë¶€ë¶„ì— ìˆ˜ë¶„ì„ ê³µê¸‰í•˜ë©´ì„œë„ ìœ ë¶„ì„ ì¡°ì ˆí•  ìˆ˜ ìžˆëŠ” ì œí’ˆì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ì„¸ëŸ¼**:\n",
      "   - í•˜ì´ì•Œë£¨ë¡ ì‚° ì„¸ëŸ¼: ìˆ˜ë¶„ ê³µê¸‰ì„ í†µí•´ ê±´ì¡°í•œ ë¶€ìœ„ë¥¼ ì´‰ì´‰í•˜ê²Œ ìœ ì§€í•´ì¤ë‹ˆë‹¤.\n",
      "   - ë¹„íƒ€ë¯¼ C ì„¸ëŸ¼: í”¼ë¶€ í†¤ì„ ê³ ë¥´ê²Œ í•˜ê³  ë°ê²Œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.\n",
      "\n",
      "4. **ëª¨ì´ìŠ¤ì²˜ë¼ì´ì €**:\n",
      "   - ì ¤ í¬ë¦¼: ìœ ë¶„ì´ ì ê³  ìˆ˜ë¶„ ê³µê¸‰ì´ ë›°ì–´ë‚œ ì œí’ˆìœ¼ë¡œ, ë³µí•©ì„± í”¼ë¶€ì— ì í•©í•©ë‹ˆë‹¤.\n",
      "   - ìœ ë¶„ì´ ì ì€ ìˆ˜ë¶„ í¬ë¦¼: ìœ ë¶„ê¸°ë¥¼ ìµœì†Œí™”í•˜ë©´ì„œ ìˆ˜ë¶„ì„ ì¶©ë¶„ížˆ ê³µê¸‰í•´ì£¼ëŠ” ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”.\n",
      "\n",
      "5. **ì„ í¬ë¦¼**:\n",
      "   - ë¬´ê¸°ìžì°¨(ë¬¼ë¦¬ì  ìžì™¸ì„  ì°¨ë‹¨ì œ): ë¯¼ê°í•œ í”¼ë¶€ì—ë„ ì í•©í•˜ë©°, ìœ ë¶„ì´ ì ì–´ ë³µí•©ì„± í”¼ë¶€ì— ìž˜ ë§žìŠµë‹ˆë‹¤.\n",
      "\n",
      "6. **ë§ˆìŠ¤í¬íŒ©**:\n",
      "   - ìˆ˜ë¶„ ê³µê¸‰ ë§ˆìŠ¤í¬: ì¼ì£¼ì¼ì— 1-2íšŒ ì‚¬ìš©í•˜ì—¬ í”¼ë¶€ì— ì¶©ë¶„í•œ ìˆ˜ë¶„ì„ ê³µê¸‰í•´ì¤ë‹ˆë‹¤.\n",
      "   - ì í†  ë§ˆìŠ¤í¬: Tì¡´ì˜ ê³¼ë„í•œ ìœ ë¶„ì„ ì œê±°í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì™¸ì—ë„ ì œí’ˆì„ ì„ íƒí•  ë•Œì—ëŠ” ìžì‹ ì˜ í”¼ë¶€ì— ì•Œë ˆë¥´ê¸°ê°€ ì—†ëŠ”ì§€, ê·¸ë¦¬ê³  ì„±ë¶„ì´ ìˆœí•œì§€ë¥¼ ê³ ë ¤í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ìƒˆë¡œìš´ ì œí’ˆì„ ì‚¬ìš©í•˜ê¸° ì „ì— í•­ìƒ íŒ¨ì¹˜ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "respone = chain.invoke({\"input\" : \"ë³µí•©ì„± í”¼ë¶€ì— ë§žëŠ” í™”ìž¥í’ˆ ì¶”ì²œ í•´ì¤˜\"})\n",
    "print(respone.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bd2da860-aa8b-49f2-901c-4f6082d356f5-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"human\" : \"ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤ ì œ ì´ë¦„ì€ ì§€ìˆ˜ìž…ë‹ˆë‹¤\"}, {\"ai\" : respone.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¼ë¡ ìž…ë‹ˆë‹¤! ì´ì „ì— ë“œë¦° ì •ë³´ë¥¼ ë‹¤ì‹œ ìš”ì•½í•´ë“œë¦´ê²Œìš”. ë³µí•©ì„± í”¼ë¶€ì— ì í•©í•œ í™”ìž¥í’ˆ ì¶”ì²œì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **í´ë Œì €**: ì ¤ íƒ€ìž… í´ë Œì €, ì˜ˆë¥¼ ë“¤ì–´ ì„¸íƒ€í•„ ì  í‹€ ìŠ¤í‚¨ í´ë Œì €.\n",
      "2. **í† ë„ˆ**: ì•Œì½”ì˜¬ í”„ë¦¬ í† ë„ˆ, ì˜ˆë¥¼ ë“¤ì–´ í‚¤ì—˜ì˜ ì¹¼ë Œë“ˆë¼ í—ˆë²Œ ì—‘ìŠ¤íŠ¸ëž™íŠ¸ í† ë„ˆ.\n",
      "3. **ì„¸ëŸ¼**: í•˜ì´ì•Œë£¨ë¡ ì‚° ì„¸ëŸ¼, ì˜ˆë¥¼ ë“¤ì–´ ë” ì˜¤ë””ë„ˆë¦¬ í•˜ì´ì•Œë£¨ë¡ ì‚° 2% + B5 ì„¸ëŸ¼.\n",
      "4. **ëª¨ì´ìŠ¤ì²˜ë¼ì´ì €**: ì˜¤ì¼ í”„ë¦¬ ì ¤ í¬ë¦¼, ì˜ˆë¥¼ ë“¤ì–´ ë‰´íŠ¸ë¡œì§€ë‚˜ í•˜ì´ë“œë¡œ ë¶€ìŠ¤íŠ¸ ì›Œí„° ì ¤.\n",
      "5. **ì„ í¬ë¦¼**: ë…¼ì½”ë©”ë„ì œë‹‰ ì„ í¬ë¦¼, ì˜ˆë¥¼ ë“¤ì–´ ë¼ë¡œìŠˆí¬ì œ ì•ˆë—„ë¦¬ì˜¤ìŠ¤ ìš¸íŠ¸ë¼ ë¼ì´íŠ¸ í”Œë£¨ì´ë“œ SPF50+.\n",
      "6. **ë§ˆìŠ¤í¬**: í´ë ˆì´ ë§ˆìŠ¤í¬, ì˜ˆë¥¼ ë“¤ì–´ ì´ë‹ˆìŠ¤í”„ë¦¬ ìˆ˜í¼ í™”ì‚°ì†¡ì´ ëª¨ê³µ ë§ˆìŠ¤í¬.\n",
      "\n",
      "ì´ ì œí’ˆë“¤ì€ ë³µí•©ì„± í”¼ë¶€ì˜ ê· í˜•ì„ ë§žì¶”ê³  ê±´ê°•í•˜ê²Œ ìœ ì§€í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì‚¬ìš© ì „ì—ëŠ” ê°œì¸ í”¼ë¶€ì— ë§žëŠ”ì§€ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë” ê¶ê¸ˆí•œ ì ì´ ìžˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "respone = chain.invoke({\"input\" : \"ì´ì „ì— ì•Œë ¤ì¤€ ì •ë³´ ë‹¤ì‹œ ì•Œë ¤ì¤˜\"})\n",
    "print(respone.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_chain(memory, query):\n",
    "    chat_history = RunnablePassthrough.assign(\n",
    "        chat_history = RunnableLambda(memory.load_memory_variables) | itemgetter(memory.memory_key)\n",
    "    )\n",
    "    llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0)\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"ë„ˆëŠ” ì¹œì ˆí•œ í™”ìž¥í’ˆ ì•ˆë‚´ ê°€ì´ë“œì•¼\"),\n",
    "            MessagesPlaceholder(variable_name = \"chat_history\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ]\n",
    "    )\n",
    "    chain = chat_history | prompt | llm | StrOutputParser()\n",
    "    # StrOutputParser() : ì¶œë ¥ëœëŠ ê°’ì„ ìžë™ìœ¼ë¡œ íŒŒì‹±(ë¶ˆí•„ìš”í•œ ê°œí–‰ë¬¸ìž, íŠ¹ìˆ˜ê¸°í˜¸ ë“±ì„ ìžë™ìœ¼ë¡œ ì²˜ë¦¬)\n",
    "    answer = chain.invoke({\"input\" : query})\n",
    "    memory.save_context(inputs = {\"human\" : query}, outputs = {\"ai\" : answer})\n",
    "    # ì¸í’‹ ì•„ì›ƒí’‹ì„ ëª…ì‹œì ìœ¼ë¡œ ì œê³µí•˜ìž\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì›Œë“œ í´ë¼ìš°ë“œ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install wordcloud matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
